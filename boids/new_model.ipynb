{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import itertools\n",
    "from typing import List, Union, Sequence\n",
    "\n",
    "\n",
    "# Third-party library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from numpy import ndarray\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from PIL import Image\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import ChebConv\n",
    "from torch_geometric.nn.conv import GeneralConv\n",
    "\n",
    "# Project-specific import\n",
    "from Utils_GAN.classes import DynamicGraphTemporalSignal, GConvGRU, BoidDatasetLoader,RecurrentGCN\n",
    "from Utils_GAN.classes import Encoder,Decoder,GraphSeqGenerator\n",
    "from Utils_GAN.classes import GraphSeqDiscriminator,GraphSeqGenerator\n",
    "\n",
    "\n",
    "from Utils_GAN.subfunctions import temporal_signal_split, train,plot_predictions,test,create_video_from_images\n",
    "from Utils_GAN.subfunctions import train_generator,test_generator,test_generator_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Now: Grabbing Parts of Pytorch Geometric Temporal As Having Difficulty Setting Up The Environment For It"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up BoidDatasetLoader To Load Entire Dataset\n",
    "Following Example of EnglandCovidDatasetLoader from Pytorch Geometric Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoidDatasetLoader(object):\n",
    "    \"\"\"\n",
    "    The BoidDatasetLoader class is designed to load and process the Boid Dataset.\n",
    "    It reads data from CSV files, processes it, and prepares it for further analysis or modeling. The class performs the\n",
    "    following key functions:\n",
    "\n",
    "    1. Initialization (__init__ method):\n",
    "       - Calls the _read_data method to load and preprocess the data.\n",
    "\n",
    "    2. Data Reading and Preprocessing (_read_data method):\n",
    "       - Reads simulation data from 'simulation.csv' and 'simulation_edges.csv'.\n",
    "       - Drops the 'Simulation' column from both dataframes.\n",
    "       - Renames columns to standardize the naming convention (e.g., 'Boids' to 'BoidID', 'Boid_i' to 'BoidID_i').\n",
    "       - Stores the cleaned dataframes in the _dataset attribute.\n",
    "       - Calls the _process_dataset method to further process the data and extract features, edges, and edge weights.\n",
    "\n",
    "    3. Dataset Processing (_process_dataset method):\n",
    "       - Groups the simulation data by 'Timestep'.\n",
    "       - Initializes lists to store edge indices, node features, and distances.\n",
    "       - Iterates over each timestep to extract relevant data for that timestep.\n",
    "       - Converts the dataframes to NumPy arrays for efficient computation.\n",
    "       - Creates a dictionary to map BoidID to coordinates.\n",
    "       - Uses vectorized operations to calculate distances between boids with edges.\n",
    "\n",
    "    4. Getting Features and Edge Weights (_get_edge_weights() and _get_features() methods):\n",
    "        - Normalized features and _edge_weights using min-max normalization\n",
    "        - Attributes are now normalized when called and returned\n",
    "\n",
    "    5. Getting Target (_get_target() method):\n",
    "        - If t is the current index of our dataset, then t+1 is the target\n",
    "        - Contains the node features of the graph at t+1\n",
    "        - Will probably not used this as wouldnt work entirely for more than 1 timestep prediction\n",
    "\n",
    "    Attributes:\n",
    "        _dataset: A tuple containing the cleaned simulation data and edge data.\n",
    "        features: Node features extracted from the simulation data.\n",
    "        _edges: Edge indices representing connections between boids.\n",
    "        _edge_weights: Weights of the edges, which could represent distances or other metrics.\n",
    "\n",
    "    Methods:\n",
    "        __init__(): Initializes the class and reads the data.\n",
    "        _read_data(): Reads and preprocesses the data from CSV files.\n",
    "        _process_dataset(sim_df, sim_edges_df): Processes the dataset to extract features, edges, and edge weights.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._read_data()\n",
    "\n",
    "    def _read_data(self):\n",
    "        path_to_sim = '../data/simulation.csv'\n",
    "        path_to_sim_edges = '../data/simulation_edges.csv'\n",
    "        sim_df = pd.read_csv(path_to_sim)\n",
    "        sim_edges_df = pd.read_csv(path_to_sim_edges)\n",
    "\n",
    "        sim_df.drop(columns='Simulation', inplace=True)\n",
    "        sim_df.rename(columns={'Boids':'BoidID'}, inplace=True)\n",
    "\n",
    "        sim_edges_df.drop(columns='Simulation', inplace=True)\n",
    "        sim_edges_df.rename(columns={'Boid_i':'BoidID_i', 'Boid_j':'BoidID_j'}, inplace=True)\n",
    "        \n",
    "        self._dataset = (sim_df, sim_edges_df)\n",
    "        self.features, self._edges, self._edge_weights = self._process_dataset(self._dataset[0], self._dataset[1])\n",
    "\n",
    "    def _process_dataset(self, sim_df, sim_edges_df):\n",
    "        # Group the dataframes by 'Timestep'\n",
    "        sim_grouped = sim_df.groupby('Timestep')\n",
    "        edges_grouped = sim_edges_df.groupby('Timestep')\n",
    "        \n",
    "        # Initialize lists to store edge indices and node features\n",
    "        edge_indices = []\n",
    "        node_features = []\n",
    "        \n",
    "        distances = []\n",
    "\n",
    "        # Iterate over each group\n",
    "        for timestep, _ in sim_grouped:\n",
    "            # Extract relevant columns for the current timestep\n",
    "            timestep_df = sim_grouped.get_group(timestep)[['x', 'y', 'dx', 'dy', 'BoidID']]\n",
    "            timestep_edges_df = edges_grouped.get_group(timestep)[['BoidID_i', 'BoidID_j']]\n",
    "            \n",
    "            # Convert dataframes to numpy arrays\n",
    "            node_array = timestep_df[['x', 'y', 'dx', 'dy']].to_numpy()\n",
    "            edge_array = timestep_edges_df.to_numpy().T\n",
    "\n",
    "            # Create a dictionary to map BoidID to coordinates\n",
    "            boid_coords = {boid_id: coords for boid_id, coords in zip(timestep_df['BoidID'], timestep_df[['x', 'y']].values)}\n",
    "            \n",
    "            # Get coordinates for boids involved in edges\n",
    "            boid_i_coords = np.array([boid_coords[boidid_i] for boidid_i in edge_array[0]])\n",
    "            boid_j_coords = np.array([boid_coords[boidid_j] for boidid_j in edge_array[1]])\n",
    "            \n",
    "            # Calculate distances using vectorized operations\n",
    "            timestep_distances = np.linalg.norm(boid_i_coords - boid_j_coords, axis=1)\n",
    "            \n",
    "            distances.append(timestep_distances)\n",
    "\n",
    "            # Append the numpy arrays to the respective lists\n",
    "            edge_indices.append(edge_array)\n",
    "            node_features.append(node_array)\n",
    "\n",
    "        # Return the lists of edge indices and node features\n",
    "        return node_features, edge_indices, distances\n",
    "\n",
    "    def _compute_feature_min_max(self, feature_list):\n",
    "        \"\"\"\n",
    "        Compute the minimum and maximum of features across all node features.\n",
    "\n",
    "        Parameters:\n",
    "        all_node_features (list of np.ndarray): List of numpy arrays containing node features.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing two numpy arrays: (final_min, final_max).\n",
    "        \"\"\"\n",
    "        if not feature_list:\n",
    "            raise ValueError(\"The input list 'all_node_features' is empty.\")\n",
    "        \n",
    "        # Initialize final_min and final_max with appropriate dimensions\n",
    "        if len(feature_list[0].shape) == 0:\n",
    "            raise ValueError('The input list is missing node features') \n",
    "        \n",
    "        if len(feature_list[0].shape) == 1:\n",
    "            feature_dim = 1\n",
    "            axis_val = None\n",
    "            final_min = float('inf')\n",
    "            final_max = float('-inf')\n",
    "        else:\n",
    "            feature_dim = feature_list[0].shape[1]\n",
    "            axis_val = 0\n",
    "            final_min = np.array([float('inf')] * feature_dim)\n",
    "            final_max = np.array([float('-inf')] * feature_dim)\n",
    "        \n",
    "        # Iterate through all node features to compute final_min and final_max\n",
    "        for features in feature_list:\n",
    "            curr_max = np.max(features, axis=axis_val)\n",
    "            curr_min = np.min(features, axis=axis_val)\n",
    "            final_max = np.max(np.array([final_max, curr_max]), axis=0)\n",
    "            final_min = np.min(np.array([final_min, curr_min]), axis=0)\n",
    "        \n",
    "        return final_min, final_max\n",
    "    \n",
    "    def _minmax_scale(self, feature_list, final_min, final_max):\n",
    "        normalized = []\n",
    "        for i in range(len(feature_list)):\n",
    "            X = feature_list[i]\n",
    "            X_std = (X - final_min) / (final_max - final_min)\n",
    "            normalized.append(X_std)\n",
    "        return normalized\n",
    "\n",
    "    def undo_minmax_scale(self, normalized_feature_list, final_min, final_max):\n",
    "        unnormalized = []\n",
    "        for i in range(len(normalized_feature_list)):\n",
    "            X_std = normalized_feature_list[i]\n",
    "            X_scaled = X_std * (final_max - final_min) + final_min\n",
    "            unnormalized.append(X_scaled)\n",
    "        return unnormalized\n",
    "    \n",
    "\n",
    "    def _get_edge_weights(self):\n",
    "        self.min_edge_weight, self.max_edge_weight = self._compute_feature_min_max(self._edge_weights)\n",
    "        self._edge_weights = self._minmax_scale(self._edge_weights, self.min_edge_weight, self.max_edge_weight)\n",
    "\n",
    "    def _get_features(self):\n",
    "        self.min_features, self.max_features = self._compute_feature_min_max(self.features)\n",
    "        self.features = self._minmax_scale(self.features, self.min_features, self.max_features)\n",
    "    def _get_targets(self):\n",
    "        self.targets = [self.features[i] for i in range(1, len(self.features))]\n",
    "\n",
    "\n",
    "    def get_dataset(self) -> DynamicGraphTemporalSignal:\n",
    "\n",
    "        self._get_edge_weights()\n",
    "        self._get_features()\n",
    "        self._get_targets()\n",
    "        dataset = DynamicGraphTemporalSignal(\n",
    "            self._edges[:len(self.features)-1], \n",
    "            self._edge_weights[:len(self.features)-1], \n",
    "            self.features[:len(self.features)-1], \n",
    "            self.targets\n",
    "        )\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset kernel if not working\n",
    "loader = BoidDatasetLoader()\n",
    "dataset = loader.get_dataset()\n",
    "dataset.snapshot_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.min_features[0:2], loader.max_features[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset Into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again from https://github.com/benedekrozemberczki/pytorch_geometric_temporal/blob/master/torch_geometric_temporal/signal/train_test_split.py\n",
    "\n",
    "def temporal_signal_split(data_iterator, train_ratio=0.8):\n",
    "    train_snapshots = int(data_iterator.snapshot_count * train_ratio)\n",
    "    train_iterator = data_iterator[0:train_snapshots]\n",
    "    test_iterator = data_iterator[train_snapshots:]\n",
    "    return train_iterator, test_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = temporal_signal_split(dataset)\n",
    "\n",
    "train_dataset.snapshot_count, test_dataset.snapshot_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GConvGRU For Recurrent Layer In Our GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Graph Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Training a basic model for tesiting purpose\n",
    "model = RecurrentGCN(node_features=4, filters=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    for seq_start in tqdm(range(0, train_dataset.snapshot_count - 5, 5)):\n",
    "        h_t_prev = None\n",
    "        for i in range(5):\n",
    "            snapshot = train_dataset[seq_start+i]\n",
    "            y_hat, h_t = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, h_t_prev)\n",
    "            h_t_prev = h_t\n",
    "        cost = F.mse_loss(y_hat, snapshot.y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecurrentGCN(node_features=4, filters=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train(train_dataset, 10, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_dataset, model,loader=loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Example usage\n",
    "#create_video_from_images('../generator_test_plots_at_epoch_10', 'generator_test_plots_at_epoch_10.2.mp4', fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_video_from_images('../generator2_test_plots_at_epoch_30', 'generator2_test_plots_at_epoch_30.mp4', fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on GAN [Generator: (Encoder, Decoder)] [Discriminator: (Encoder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSeqGenerator(torch.nn.Module):\n",
    "    def __init__(self, node_feat_dim, enc_hidden_dim, enc_latent_dim, dec_hidden_dim, pred_horizon, min_max_x, min_max_y, min_max_edge_weight, visualRange, device):\n",
    "        super(GraphSeqGenerator, self).__init__()\n",
    "        self.encoder = Encoder(node_feat_dim, enc_hidden_dim, enc_latent_dim)\n",
    "        self.decoder = Decoder(enc_latent_dim, dec_hidden_dim, node_feat_dim)\n",
    "        self.out_steps = pred_horizon\n",
    "        self.min_x, self.max_x = min_max_x\n",
    "        self.min_y, self.max_y = min_max_y\n",
    "        self.min_edge_weight, self.max_edge_weight = min_max_edge_weight\n",
    "        self.visualRange = visualRange\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def _compute_edge_index_and_weight(self, y_hat):\n",
    "        # Not designed for batches :/\n",
    "        # Grab x and y features\n",
    "        y_hat_x = y_hat[:, 0].detach() # originally I moved these to cpu but now it depends on the 'device'\n",
    "        y_hat_y = y_hat[:, 1].detach()\n",
    "\n",
    "        # Undo normalization\n",
    "        y_hat_x = y_hat_x * (self.max_x - self.min_x) + self.min_x\n",
    "        y_hat_y = y_hat_y * (self.max_y - self.min_y) + self.min_y\n",
    "\n",
    "        # Compute the distance of all points and include that edge if its less than visualRange\n",
    "        coords = torch.stack((y_hat_x, y_hat_y), dim=1)\n",
    "        distances = torch.cdist(coords, coords, p=2)\n",
    "\n",
    "        # Get indices where distance is less than visualRange\n",
    "        edge_indices = torch.where((distances < self.visualRange) & (distances > 0)) # returns a tuple with indices\n",
    "        \n",
    "        # Create edge_index and edge_attr\n",
    "        edge_index = torch.vstack((edge_indices[0], edge_indices[1]))\n",
    "        edge_weight = distances[edge_indices]\n",
    "\n",
    "        #Normalize edge_weight\n",
    "        edge_weight = (edge_weight - self.min_edge_weight) / (self.max_edge_weight - self.min_edge_weight)\n",
    "        \n",
    "        edge_index = edge_index.to(device=self.device)\n",
    "        edge_weight = edge_weight.to(device=self.device)\n",
    "\n",
    "        return edge_index, edge_weight\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, sequence, h_enc, h_dec):\n",
    "        # Warmup Section\n",
    "        for i in range(sequence.snapshot_count):\n",
    "            snapshot = sequence[i]\n",
    "            snapshot_x = snapshot.x.to(self.device)\n",
    "            snapshot_edge_index = snapshot.edge_index.to(self.device)\n",
    "            snapshot_edge_attr = snapshot.edge_attr.to(self.device)\n",
    "\n",
    "            z, h_enc_0 = self.encoder(snapshot_x, snapshot_edge_index, snapshot_edge_attr, h_enc)\n",
    "            # This part doesnt have the random vector in the hidden state so I need to add it hear \n",
    "            y_hat, h_dec_0 = self.decoder(z, snapshot_edge_index, snapshot_edge_attr, h_dec)\n",
    "\n",
    "            h_enc = h_enc_0\n",
    "            h_dec = h_dec_0\n",
    "\n",
    "        y_hat_features = []\n",
    "        y_hat_edge_indices = []\n",
    "        y_hat_edge_attrs = []\n",
    "        y_hat_features.append(y_hat)\n",
    "        y_hat_edge_index, y_hat_edge_attr = self._compute_edge_index_and_weight(y_hat)\n",
    "        y_hat_edge_indices.append(y_hat_edge_index)\n",
    "        y_hat_edge_attrs.append(y_hat_edge_attr)\n",
    "        \n",
    "        # Prediction Section\n",
    "        for _ in range(self.out_steps-1):\n",
    "            y_hat_edge_index, y_hat_edge_attr = self._compute_edge_index_and_weight(y_hat)\n",
    "\n",
    "            z, h_enc_0 = self.encoder(y_hat, y_hat_edge_index, y_hat_edge_attr, h_enc)\n",
    "            y_hat, h_dec_0 = self.decoder(z, y_hat_edge_index, y_hat_edge_attr, h_dec)\n",
    "\n",
    "            y_hat_features.append(y_hat)\n",
    "            y_hat_edge_index, y_hat_edge_attr = self._compute_edge_index_and_weight(y_hat)\n",
    "            y_hat_edge_indices.append(y_hat_edge_index)\n",
    "            y_hat_edge_attrs.append(y_hat_edge_attr)\n",
    "            \n",
    "        # Need to save it in cpu\n",
    "        y_hat_edge_indices = [y_hat_edge_index.cpu() for y_hat_edge_index in y_hat_edge_indices]\n",
    "        y_hat_edge_attrs = [y_hat_edge_attr.cpu() for y_hat_edge_attr in y_hat_edge_attrs]\n",
    "        y_hat_features = [y_hat_feature.cpu() for y_hat_feature in y_hat_features]\n",
    "\n",
    "        y_hat_seq = DynamicGraphTemporalSignal(y_hat_edge_indices, y_hat_edge_attrs, y_hat_features, [None]*self.out_steps)\n",
    "        return y_hat_features, y_hat_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSeqDiscriminator(torch.nn.Module):\n",
    "    def __init__(self, node_feat_dim, enc_hidden_dim, enc_latent_dim, pred_horizon, device):\n",
    "        super(GraphSeqDiscriminator, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(node_feat_dim, enc_hidden_dim, enc_latent_dim)\n",
    "        self.linear = torch.nn.Linear(enc_latent_dim, 1)\n",
    "        self.out_steps = pred_horizon\n",
    "        self.device = device\n",
    "\n",
    "    \n",
    "    def forward(self, sequence, h_enc, shouldDetach=False):\n",
    "        for i in range(sequence.snapshot_count):\n",
    "            snapshot = sequence[i]\n",
    "            snapshot_x = snapshot.x.to(self.device)\n",
    "            snapshot_edge_index = snapshot.edge_index.to(self.device)\n",
    "            snapshot_edge_attr = snapshot.edge_attr.to(self.device)\n",
    "\n",
    "            if shouldDetach:\n",
    "                snapshot_x = snapshot_x.detach()\n",
    "                snapshot_edge_index = snapshot_edge_index.detach()\n",
    "                snapshot_edge_attr = snapshot_edge_attr.detach()\n",
    "\n",
    "            z, h_enc_0 = self.encoder(snapshot_x, snapshot_edge_index, snapshot_edge_attr, h_enc)\n",
    "            h_enc = h_enc_0\n",
    "        \n",
    "        z = F.relu(z)\n",
    "\n",
    "        # Apply global mean pooling across the node dimension (dim=0) to aggregate node features\n",
    "        z_pooled = z.mean(dim=0)\n",
    "        out = self.linear(z_pooled)\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        return out, h_enc_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(train_data, num_epochs, generator, discriminator, criterion, optimizerG, optimizerD, device, k=1, window=8, delay=0, horizon=1, stride=1):\n",
    "    \"\"\"\n",
    "    Trains the given model using the provided training data.\n",
    "\n",
    "    Args:\n",
    "        train_data (Dataset): The dataset containing the training data.\n",
    "        num_epochs (int): The number of epochs to train the model.\n",
    "        model (nn.Module): The model to be trained.\n",
    "        optimizer (Optimizer): The optimizer used for training the model.\n",
    "        window (int, optional): The size of the input sequence window. Defaults to 8.\n",
    "        delay (int, optional): The delay between the input sequence and the target sequence. Defaults to 0.\n",
    "        horizon (int, optional): The prediction horizon. Defaults to 1.\n",
    "        stride (int, optional): The stride for iterating over the training data. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    total_timesteps = train_data.snapshot_count\n",
    "    sample_span = window + delay + horizon\n",
    "    \n",
    "\n",
    "    generator.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch: {epoch+1}/{num_epochs}')\n",
    "        epoch_cost = 0\n",
    "        for start in tqdm(range(0, total_timesteps - sample_span + 1, stride), desc='Training'):\n",
    "            input_seq = train_data[start:start + window]\n",
    "            y_seq = train_data[start + window + delay: start + window + delay + horizon]\n",
    "\n",
    "\n",
    "            y_hat_seq_feats, y_hat_seq = generator(input_seq, None, None)\n",
    "\n",
    "\n",
    "            # Discriminator Step\n",
    "            discriminator.zero_grad()\n",
    "\n",
    "            output_of_real, _ = discriminator(y_seq, h_enc=None)\n",
    "\n",
    "            errD_real = criterion(output_of_real, torch.ones(1, device=device))\n",
    "\n",
    "            errD_real.backward()\n",
    "\n",
    "            output_of_fake, _ = discriminator(y_hat_seq, h_enc=None, shouldDetach=True)\n",
    "            errD_fake = criterion(output_of_fake, torch.ones(1, device=device))\n",
    "\n",
    "            errD_fake.backward()\n",
    "\n",
    "            errD = errD_real + errD_fake\n",
    "\n",
    "            optimizerD.step()\n",
    "\n",
    "            # Generator Step\n",
    "            generator.zero_grad()\n",
    "            min_mse_loss = float('inf')\n",
    "            best_y_hat_seq = None\n",
    "\n",
    "            for _ in range(k):\n",
    "                y_hat_seq_feats, y_hat_seq = generator(input_seq, None, None)\n",
    "                output_of_fake2, _ = discriminator(y_hat_seq, h_enc=None)\n",
    "\n",
    "                y_hat = torch.stack([y_hat_seq[i].x for i in range(y_hat_seq.snapshot_count)], dim=0).to(device=device)\n",
    "                y_actual = torch.stack([y_seq[i].x for i in range(y_seq.snapshot_count)], dim=0).to(device=device)\n",
    "\n",
    "                mse_loss = F.mse_loss(y_hat, y_actual)\n",
    "                if mse_loss < min_mse_loss:\n",
    "                    min_mse_loss = mse_loss\n",
    "                    best_y_hat_seq = y_hat_seq\n",
    "\n",
    "            output_of_fake2, _ = discriminator(best_y_hat_seq, h_enc=None)\n",
    "\n",
    "            errG = criterion(output_of_fake2, torch.ones(1, device=device))\n",
    "\n",
    "            errG += min_mse_loss\n",
    "\n",
    "            errG.backward()\n",
    "\n",
    "            optimizerG.step()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "generator = GraphSeqGenerator(node_feat_dim=4,\n",
    "                              enc_hidden_dim=32,\n",
    "                              enc_latent_dim=16,\n",
    "                              dec_hidden_dim=32,\n",
    "                              pred_horizon=8,\n",
    "                              min_max_x=(loader.min_features[0], loader.max_features[0]),\n",
    "                              min_max_y=(loader.min_features[1], loader.max_features[1]),\n",
    "                              min_max_edge_weight=(loader.min_edge_weight, loader.max_edge_weight),\n",
    "                              visualRange=75,\n",
    "                              device=device,\n",
    "                            )\n",
    "generator.to(device)\n",
    "\n",
    "discriminator = GraphSeqDiscriminator(node_feat_dim=4,\n",
    "                                      enc_hidden_dim=32,\n",
    "                                      enc_latent_dim=16,\n",
    "                                      pred_horizon=8,\n",
    "                                      device=device)\n",
    "discriminator.to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizerG = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "optimizerD = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "train_gan(train_dataset, 1, generator, discriminator, criterion, optimizerG, optimizerD, device, k=6, window=8, horizon=8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
