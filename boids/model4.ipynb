{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import torch\n",
    "from typing import List\n",
    "from typing import Union\n",
    "from numpy import ndarray\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import ChebConv\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from PIL import Image\n",
    "from torch_geometric.nn.conv import GeneralConv\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing Simulation Data From CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sim = '../data/simulation.csv'\n",
    "sim_df = pd.read_csv(path_to_sim)\n",
    "sim_df.drop(columns='Simulation', inplace=True)\n",
    "sim_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Boid_i</th>\n",
       "      <th>Boid_j</th>\n",
       "      <th>Timestep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Boid_i  Boid_j  Timestep\n",
       "0       0      39         0\n",
       "1       0      57         0\n",
       "2       1      32         0\n",
       "3       1      34         0\n",
       "4       1      83         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_sim_edges = '../data/simulation_edges.csv'\n",
    "sim_edges_df = pd.read_csv(path_to_sim_edges)\n",
    "sim_edges_df.drop(columns='Simulation', inplace=True)\n",
    "sim_edges_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Dataframes for all edge indices and all node features per timetstep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_to_sim_edges = '../data/simulation_edges.csv'\n",
    "sim_edges_df = pd.read_csv(path_to_sim_edges)\n",
    "\n",
    "path_to_sim = '../data/simulation.csv'\n",
    "sim_df = pd.read_csv(path_to_sim)\n",
    "\n",
    "\n",
    "sim_edges_df.head(5)\n",
    "\n",
    "frame_rate = 1\n",
    "\n",
    "sim_edges_df= sim_edges_df[sim_edges_df['Timestep']% frame_rate== 0]\n",
    "sim_df= sim_df[sim_df['Timestep']% frame_rate== 0]\n",
    "\n",
    "sim_edges_df_final = sim_edges_df[sim_edges_df['Simulation'] == 0]\n",
    "sim_df_final = sim_df[sim_df['Simulation'] == 0]\n",
    "\n",
    "testing_edges = sim_edges_df[sim_edges_df['Simulation'] == 1]\n",
    "testing = sim_df[sim_df['Simulation'] == 1]\n",
    "\n",
    "total_length = len(testing)\n",
    "total_length_edges = len(testing_edges)\n",
    "\n",
    "subset_length = math.ceil(total_length * 0.2)  # Get 20% of the total data\n",
    "subset_length_edges = math.ceil(total_length_edges * 0.2)  # Get 20% of the total data\n",
    "\n",
    "testing_edges_20 = testing_edges[:subset_length_edges]\n",
    "testing_20 = testing[:subset_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dfs(sim_df, sim_edges_df):\n",
    "    # Group the dataframes by 'Timestep'\n",
    "    sim_grouped = sim_df.groupby('Timestep')\n",
    "    edges_grouped = sim_edges_df.groupby('Timestep')\n",
    "    \n",
    "    # Initialize lists to store edge indices and node features\n",
    "    edge_indices = []\n",
    "    node_features = []\n",
    "    \n",
    "    # Iterate over each group\n",
    "    for timestep, _ in sim_grouped:\n",
    "        # Extract relevant columns for the current timestep\n",
    "        timestep_df = sim_grouped.get_group(timestep)[['x', 'y', 'dx', 'dy']]\n",
    "        timestep_edges_df = edges_grouped.get_group(timestep)[['Boid_i', 'Boid_j']]\n",
    "        \n",
    "        # Convert dataframes to numpy arrays\n",
    "        node_array = timestep_df.to_numpy()\n",
    "        edge_array = timestep_edges_df.to_numpy().T\n",
    "\n",
    "        # Append the numpy arrays to the respective lists\n",
    "        edge_indices.append(edge_array)\n",
    "        node_features.append(node_array)\n",
    "\n",
    "    # Return the lists of edge indices and node features\n",
    "    return edge_indices, node_features\n",
    "all_edge_indices_test, all_node_features_test = process_dfs(testing_20, testing_edges_20)\n",
    "all_edge_indices, all_node_features = process_dfs(sim_df, sim_edges_df)\n",
    "#all_node_features = [minmax_scale(all_node_features[i], axis=1) for i in range(len(all_node_features))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all possible combinations of edges given there are 100 nodes (boids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4950)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations = list(itertools.combinations(range(100), 2))\n",
    "all_possible_edge_indices = np.array(combinations).T\n",
    "all_possible_edge_indices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute edge attributes per timestep (whether boids are close enough and distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 10000/10000 [00:44<00:00, 224.41it/s]\n"
     ]
    }
   ],
   "source": [
    "def compute_edge_attributes(sim_df, distance_threshold=75):\n",
    "    \"\"\"\n",
    "    Compute edge attributes for each timestep in the simulation DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    sim_df (pd.DataFrame): DataFrame containing simulation data with columns 'Timestep', 'x', 'y', and 'Boids'.\n",
    "    distance_threshold (float): Distance threshold to determine if boids are close enough.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of numpy arrays containing edge attributes for each timestep.\n",
    "    \"\"\"\n",
    "    bruh = sim_df.groupby('Timestep')\n",
    "\n",
    "    all_edge_attr = []\n",
    "    for key, sim_df_t in tqdm(bruh, total=len(bruh)):\n",
    "        # Extract coordinates\n",
    "        coordinates = sim_df_t[['x', 'y']].values\n",
    "        \n",
    "        # Compute pairwise distances using scipy\n",
    "        dist_matrix = distance.cdist(coordinates, coordinates, 'euclidean')\n",
    "        \n",
    "        # Get the indices of the combinations\n",
    "        num_boids = len(coordinates)\n",
    "        combinations_array = np.array(np.triu_indices(num_boids, k=1)).T\n",
    "\n",
    "        # Filter distances and create edge attributes\n",
    "        edge_attr_t = []\n",
    "        for edge in combinations_array:\n",
    "            dist = dist_matrix[edge[0], edge[1]]\n",
    "            closeEnough = 1 if dist < distance_threshold else 0\n",
    "            edge_attr_t.append([closeEnough, dist])\n",
    "        \n",
    "        edge_attr_t = np.array(edge_attr_t)\n",
    "        all_edge_attr.append(edge_attr_t)\n",
    "    \n",
    "    return all_edge_attr\n",
    "\n",
    "# Example usage:\n",
    "all_edge_attr_test = compute_edge_attributes(testing_20)\n",
    "all_edge_attr = compute_edge_attributes(sim_df)\n",
    "#all_edge_attr = [minmax_scale(all_edge_attr[i], axis=1) for i in range(len(all_edge_attr))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing our data using min max scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_min_max(all_features_list):\n",
    "    \"\"\"\n",
    "    Compute the minimum and maximum of features across all node features.\n",
    "\n",
    "    Parameters:\n",
    "    all_node_features (list of np.ndarray): List of numpy arrays containing node features.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two numpy arrays: (final_min, final_max).\n",
    "    \"\"\"\n",
    "    if not all_features_list:\n",
    "        raise ValueError(\"The input list 'all_node_features' is empty.\")\n",
    "    \n",
    "    # Initialize final_min and final_max with appropriate dimensions\n",
    "    feature_dim = all_features_list[0].shape[1]\n",
    "    final_min = np.array([float('inf')] * feature_dim)\n",
    "    final_max = np.array([float('-inf')] * feature_dim)\n",
    "    \n",
    "    # Iterate through all node features to compute final_min and final_max\n",
    "    for features in all_features_list:\n",
    "        curr_max = np.max(features, axis=0)\n",
    "        curr_min = np.min(features, axis=0)\n",
    "        final_max = np.max(np.array([final_max, curr_max]), axis=0)\n",
    "        final_min = np.min(np.array([final_min, curr_min]), axis=0)\n",
    "    \n",
    "    return final_min, final_max\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# final_min_node_feat_test, final_max_node_feat_test = compute_feature_min_max(all_node_features_test)\n",
    "# final_min_edge_attr_test, final_max_edge_attr_test= compute_feature_min_max(all_edge_attr_test)\n",
    "\n",
    "\n",
    "final_min_node_feat, final_max_node_feat = compute_feature_min_max(all_node_features)\n",
    "final_min_edge_attr, final_max_edge_attr = compute_feature_min_max(all_edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scale(all_features_list, final_min, final_max):\n",
    "    normalized = []\n",
    "    for i in range(len(all_features_list)):\n",
    "        X = all_features_list[i]\n",
    "        X_std = (X - final_min) / (final_max - final_min)\n",
    "        normalized.append(X_std)\n",
    "    return normalized\n",
    "\n",
    "def undo_minmax_scale(all_normalized_feat_list, final_min, final_max):\n",
    "    unnormalized = []\n",
    "    for i in range(len(all_normalized_feat_list)):\n",
    "        X_std = all_normalized_feat_list[i]\n",
    "        X_scaled = X_std * (final_max - final_min) + final_min\n",
    "        unnormalized.append(X_scaled)\n",
    "    return unnormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_node_features_normalized = minmax_scale(all_node_features, final_min_node_feat, final_max_node_feat)\n",
    "all_edge_attr_normalized = minmax_scale(all_edge_attr, final_min_edge_attr, final_max_edge_attr)\n",
    "\n",
    "\n",
    "# all_node_features_normalized_test = minmax_scale(all_node_features_test, final_min_node_feat_test, final_max_node_feat_test)\n",
    "# all_edge_attr_normalized_test= minmax_scale(all_edge_attr_test, final_min_edge_attr_test, final_max_edge_attr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split our dataset such that we have sequences and next sequence graph feature nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(temporal_data, window, delay=0, horizon=1, stride=1):\n",
    "    # ONLY HORIZON=1 WORKS FOR PYTORCH TEMPORAL\n",
    "    # Idea From torch spatio temporal https://torch-spatiotemporal.readthedocs.io/en/latest/_images/sliding_window.svg\n",
    "    # Initialize lists to store input and target sequences\n",
    "    input_sequences = []\n",
    "    target_sequences = []\n",
    "    \n",
    "    # Calculate the total number of timesteps\n",
    "    total_timesteps = len(temporal_data)\n",
    "    sample_span = window + delay + horizon\n",
    "    # Iterate over the list with the given stride\n",
    "    for start in range(0, total_timesteps - sample_span + 1, stride):\n",
    "        # Extract the input sequence\n",
    "        input_seq = np.array(temporal_data[start:start + window])\n",
    "        # Extract the target sequence\n",
    "        target_seq = np.array(temporal_data[start + window + delay: start + window + delay + horizon])\n",
    "        # Append the sequences to their respective lists\n",
    "        input_sequences.append(input_seq)\n",
    "        target_sequences.append(target_seq)\n",
    "    \n",
    "    # Return the lists of input and target sequences\n",
    "    return input_sequences, target_sequences\n",
    "\n",
    "node_feature_sequences, node_feature_targets = split_dataset(all_node_features_normalized, window=5, horizon=1)\n",
    "edge_weights_sequences, edge_weights_targets = split_dataset(all_edge_attr_normalized, window=5, horizon=1)\n",
    "edge_indices_sequence = [all_possible_edge_indices for _ in range(len(node_feature_sequences))]\n",
    "\n",
    "\n",
    "# node_feature_sequence_test, node_feature_targets_test = split_dataset(all_node_features_normalized_test, window=5, horizon=1)\n",
    "# edge_weights_sequences_test, edge_weights_targets_test = split_dataset(all_edge_attr_normalized_test, window=5, horizon=1)\n",
    "# edge_indices_sequence_test = [all_possible_edge_indices for _ in range(len(node_feature_sequence_test))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CustomStaticGraphTemporalSignal that gives us a sample of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomStaticGraphTemporalSignal(object):\n",
    "    def __init__(self, edge_index: ndarray | None, \n",
    "                 edge_weight: ndarray | None, \n",
    "                 features: List[ndarray | None], \n",
    "                 targets: List[ndarray | None], \n",
    "                 **kwargs: List[ndarray]):\n",
    "        \n",
    "        self.edge_index = edge_index\n",
    "        self.edge_weight = edge_weight\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.additional_feature_keys = []\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "            self.additional_feature_keys.append(key)\n",
    "        self._check_temporal_consistency()\n",
    "        self._set_snapshot_count()\n",
    "\n",
    "    def _check_temporal_consistency(self):\n",
    "        assert len(self.features) == len(\n",
    "            self.targets\n",
    "        ), \"Temporal dimension inconsistency.\"\n",
    "        for key in self.additional_feature_keys:\n",
    "            assert len(self.targets) == len(\n",
    "                getattr(self, key)\n",
    "            ), \"Temporal dimension inconsistency.\"\n",
    "\n",
    "    def _set_snapshot_count(self):\n",
    "        self.snapshot_count = len(self.features)\n",
    "\n",
    "    def _get_edge_index(self, time_index: int):\n",
    "        if self.edge_index is None:\n",
    "            return self.edge_index[time_index]\n",
    "        else:\n",
    "            return torch.LongTensor(self.edge_index[time_index])\n",
    "\n",
    "    def _get_edge_weight(self, time_index: int):\n",
    "        if self.edge_weight is None:\n",
    "            return self.edge_weight[time_index]\n",
    "        else:\n",
    "            return torch.FloatTensor(self.edge_weight[time_index])\n",
    "\n",
    "\n",
    "    def _get_features(self, time_index: int):\n",
    "        if self.features[time_index] is None:\n",
    "            return self.features[time_index]\n",
    "        else:\n",
    "            return torch.FloatTensor(self.features[time_index])\n",
    "\n",
    "    def _get_target(self, time_index: int):\n",
    "        if self.targets[time_index] is None:\n",
    "            return self.targets[time_index]\n",
    "        else:\n",
    "            if self.targets[time_index].dtype.kind == \"i\":\n",
    "                return torch.LongTensor(self.targets[time_index])\n",
    "            elif self.targets[time_index].dtype.kind == \"f\":\n",
    "                return torch.FloatTensor(self.targets[time_index])\n",
    "\n",
    "    def _get_additional_feature(self, time_index: int, feature_key: str):\n",
    "        feature = getattr(self, feature_key)[time_index]\n",
    "        if feature.dtype.kind == \"i\":\n",
    "            return torch.LongTensor(feature)\n",
    "        elif feature.dtype.kind == \"f\":\n",
    "            return torch.FloatTensor(feature)\n",
    "\n",
    "    def _get_additional_features(self, time_index: int):\n",
    "        additional_features = {\n",
    "            key: self._get_additional_feature(time_index, key)\n",
    "            for key in self.additional_feature_keys\n",
    "        }\n",
    "        return additional_features\n",
    "    def __getitem__(self, time_index: Union[int, slice]):\n",
    "        if isinstance(time_index, slice):\n",
    "            snapshot = CustomStaticGraphTemporalSignal(\n",
    "                self.edge_index[time_index],\n",
    "                self.edge_weight[time_index],\n",
    "                self.features[time_index],\n",
    "                self.targets[time_index],\n",
    "                **{key: getattr(self, key)[time_index] for key in self.additional_feature_keys}\n",
    "            )\n",
    "        else:\n",
    "            x = self._get_features(time_index)\n",
    "            edge_index = self._get_edge_index(time_index)\n",
    "            edge_weight = self._get_edge_weight(time_index)\n",
    "            y = self._get_target(time_index)\n",
    "            additional_features = self._get_additional_features(time_index)\n",
    "\n",
    "            snapshot = Data(x=x, edge_index=edge_index, edge_attr=edge_weight,\n",
    "                            y=y, **additional_features)\n",
    "        return snapshot\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.t < len(self.features):\n",
    "            snapshot = self[self.t]\n",
    "            self.t = self.t + 1\n",
    "            return snapshot\n",
    "        else:\n",
    "            self.t = 0\n",
    "            raise StopIteration\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.t = 0\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomStaticGraphTemporalSignal(edge_index=edge_indices_sequence, \n",
    "                                       edge_weight=edge_weights_sequences, \n",
    "                                       features=node_feature_sequences, \n",
    "                                       targets=node_feature_targets\n",
    "                                       )\n",
    "\n",
    "# test_data = CustomStaticGraphTemporalSignal(edge_index=edge_indices_sequence_test, \n",
    "#                                        edge_weight=edge_weights_sequences_test, \n",
    "#                                        features=node_feature_sequence_test, \n",
    "#                                        targets=node_feature_targets_test\n",
    "#                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GConvGRU for recurrent layer in our gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomChebConv(ChebConv):\n",
    "    def message(self, x_j, norm):\n",
    "        # Handle multi-dimensional edge weights by using a weighted sum or mean\n",
    "        if norm.dim() == 2:\n",
    "            norm = norm.mean(dim=1)  # Example: mean across edge features\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "\n",
    "class GConvGRU(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, K, normalization=\"sym\", bias=True):\n",
    "        super(GConvGRU, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.normalization = normalization\n",
    "        self.bias = bias\n",
    "        self._create_parameters_and_layers()\n",
    "\n",
    "    def _create_parameters_and_layers(self):\n",
    "        self.conv_x_z = CustomChebConv(self.in_channels, self.out_channels, K=self.K, normalization=self.normalization, bias=self.bias)\n",
    "        self.conv_h_z = CustomChebConv(self.out_channels, self.out_channels, K=self.K, normalization=self.normalization, bias=self.bias)\n",
    "        self.conv_x_r = CustomChebConv(self.in_channels, self.out_channels, K=self.K, normalization=self.normalization, bias=self.bias)\n",
    "        self.conv_h_r = CustomChebConv(self.out_channels, self.out_channels, K=self.K, normalization=self.normalization, bias=self.bias)\n",
    "        self.conv_x_h = CustomChebConv(self.in_channels, self.out_channels, K=self.K, normalization=self.normalization, bias=self.bias)\n",
    "        self.conv_h_h = CustomChebConv(self.out_channels, self.out_channels, K=self.K, normalization=self.normalization, bias=self.bias)\n",
    "\n",
    "    def _set_hidden_state(self, X, H):\n",
    "        if H is None:\n",
    "            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n",
    "        return H\n",
    "\n",
    "    def _calculate_update_gate(self, X, edge_index, edge_weight, H, lambda_max):\n",
    "        Z = self.conv_x_z(X, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        Z = Z + self.conv_h_z(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        Z = torch.sigmoid(Z)\n",
    "        return Z\n",
    "\n",
    "    def _calculate_reset_gate(self, X, edge_index, edge_weight, H, lambda_max):\n",
    "        R = self.conv_x_r(X, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        R = R + self.conv_h_r(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        R = torch.sigmoid(R)\n",
    "        return R\n",
    "\n",
    "    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R, lambda_max):\n",
    "        H_tilde = self.conv_x_h(X, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        H_tilde = H_tilde + self.conv_h_h(H * R, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        H_tilde = torch.tanh(H_tilde)\n",
    "        return H_tilde\n",
    "\n",
    "    def _calculate_hidden_state(self, Z, H, H_tilde):\n",
    "        H = Z * H + (1 - Z) * H_tilde\n",
    "        return H\n",
    "\n",
    "    def forward(self, X, edge_index, edge_weight=None, H=None, lambda_max=None):\n",
    "        H = self._set_hidden_state(X, H)\n",
    "        Z = self._calculate_update_gate(X, edge_index, edge_weight, H, lambda_max)\n",
    "        R = self._calculate_reset_gate(X, edge_index, edge_weight, H, lambda_max)\n",
    "        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R, lambda_max)\n",
    "        H = self._calculate_hidden_state(Z, H, H_tilde)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Graph Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, filters):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = GConvGRU(node_features, filters, 2)\n",
    "        self.linear = torch.nn.Linear(filters, 4)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, H=None):\n",
    "        h = self.recurrent(x, edge_index, edge_weight, H)\n",
    "        x = F.relu(h)\n",
    "        x = self.linear(x)\n",
    "        return x, h\n",
    "\n",
    "\n",
    "model = RecurrentGCN(node_features=4, filters=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(3):\n",
    "    for time, snapshot in tqdm(enumerate(train_data), desc='Train', total=train_data.snapshot_count):\n",
    "        h_t_prev = None\n",
    "        for seq_num in range(train_data[0].x.shape[0]):\n",
    "            y_hat, h_t = model(snapshot.x[seq_num], snapshot.edge_index, snapshot.edge_attr[seq_num], h_t_prev)\n",
    "            h_t_prev = h_t\n",
    "\n",
    "        cost = F.mse_loss(y_hat, snapshot.y[0])\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming undo_minmax_scale, final_min_node_feat, final_max_node_feat, and train_data are defined\n",
    "# RUN IF YOU WANT GIF (GIF COULD BE BETTER)\n",
    "\n",
    "model.eval()\n",
    "cost = 0\n",
    "frames = []\n",
    "\n",
    "for time, snapshot in tqdm(enumerate(train_data), desc='Train', total=train_data.snapshot_count):\n",
    "    h_t_prev = None\n",
    "    for seq_num in range(train_data[0].x.shape[0]):\n",
    "        y_hat, h_t = model(snapshot.x[seq_num], snapshot.edge_index, snapshot.edge_attr[seq_num], h_t_prev)\n",
    "        h_t_prev = h_t\n",
    "        \n",
    "    y_hat_scaled = undo_minmax_scale([y_hat.numpy(force=True)], final_min_node_feat, final_max_node_feat)[0]\n",
    "    y_actual_scaled = undo_minmax_scale([snapshot.y[0].numpy(force=True)], final_min_node_feat, final_max_node_feat)[0]\n",
    "\n",
    "    y_hat_scaled_x = y_hat_scaled[:, 0]\n",
    "    y_hat_scaled_y = y_hat_scaled[:, 1]\n",
    "    y_actual_scaled_x = y_actual_scaled[:, 0]\n",
    "    y_actual_scaled_y = y_actual_scaled[:, 1]\n",
    "    \n",
    "    # Plot the predicted vs actual values\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.scatter(list(y_hat_scaled_x), list(y_hat_scaled_y), label='Predicted', alpha=0.6)\n",
    "    ax.scatter(list(y_actual_scaled_x), list(y_actual_scaled_y), label='Actual', alpha=0.6)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.legend()\n",
    "    ax.set_title('Predicted vs Actual Values')\n",
    "    \n",
    "    # Save the current plot as a frame\n",
    "    fig.canvas.draw()\n",
    "    frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    frames.append(Image.fromarray(frame))\n",
    "    plt.close(fig)\n",
    "    \n",
    "    cost = cost + torch.mean((y_hat - snapshot.y[0])**2)\n",
    "    cost = cost / (time + 1)\n",
    "    cost = cost.item()\n",
    "    #print(\"MSE: {:.4f}\".format(cost))\n",
    "\n",
    "# Save frames as a GIF\n",
    "frames[0].save('predicted_vs_actual.gif', save_all=True, append_images=frames[1:], duration=500, loop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on GAN [Generator: (Encoder, Decoder)] [Discriminator: (Encoder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_recurrent_dim, output_recurrent_dim, hidden_dim, k=2):\n",
    "        super(Encoder, self).__init__()\n",
    "        # self.conv1 = GeneralConv(node_feature_dim, hidden_dim, in_edge_channels)\n",
    "        # self.conv2 = GeneralConv(hidden_dim, input_recurrent_dim, in_edge_channels)\n",
    "        self.recurrent = GConvGRU(input_recurrent_dim, output_recurrent_dim, k)\n",
    "        self.linear = torch.nn.Linear(output_recurrent_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr, H=None):\n",
    "        print(x.shape, edge_index.shape, edge_attr.shape)\n",
    "        encoder_h = self.recurrent(X=x, edge_index=edge_index, edge_weight=edge_attr, H=H)\n",
    "        encoder_h = F.relu(encoder_h)\n",
    "        print(\"Bruh\", encoder_h.shape)\n",
    "        encoder_h = self.linear(encoder_h)\n",
    "        print('Bruh2', encoder_h.shape)\n",
    "        return encoder_h\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, node_feature_dim, input_recurrent_dim, output_recurrent_dim, k=2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.recurrent = GConvGRU(input_recurrent_dim, output_recurrent_dim, k)\n",
    "        self.linear = torch.nn.Linear(output_recurrent_dim, node_feature_dim)\n",
    "\n",
    "    def forward(self, h, edge_index, edge_attr, H=None):\n",
    "        decoder_h = self.recurrent(X=h, edge_index=edge_index, edge_weight=edge_attr, H=H)\n",
    "        x = F.relu(decoder_h)\n",
    "        x = self.linear(x)\n",
    "        return x, decoder_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(4, 16, 64)\n",
    "decoder = Decoder(4, 64, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/9995 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 4]) torch.Size([2, 4950]) torch.Size([4950, 2])\n",
      "Bruh torch.Size([100, 16])\n",
      "Bruh2 torch.Size([100, 64])\n",
      "torch.Size([100, 64])\n",
      "*******************\n",
      "torch.Size([100, 16])\n",
      "torch.Size([100, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for time, snapshot in tqdm(enumerate(train_data), desc='Train', total=train_data.snapshot_count):\n",
    "        h_encoder_prev, h_decoder_prev = None, None\n",
    "        for seq_num in range(train_data[0].x.shape[0]):\n",
    "            #print(snapshot.x[seq_num].shape, snapshot.edge_index.shape, snapshot.edge_attr[seq_num][:, 1].shape,snapshot.y.shape)\n",
    "            h_encoder = encoder(snapshot.x[seq_num], snapshot.edge_index, snapshot.edge_attr[seq_num], h_encoder_prev)\n",
    "            h_t_prev = h_encoder\n",
    "            print(h_encoder.shape)\n",
    "\n",
    "            y_hat, h_decoder = decoder(h_encoder, snapshot.edge_index, snapshot.edge_attr[seq_num], h_decoder_prev)\n",
    "            h_decoder_prev = h_decoder\n",
    "            print('*******************')\n",
    "            print(h_decoder.shape)\n",
    "            print(y_hat.shape)\n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSeqGenerator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, node_features_dim, in_edge_channels, seq_length, \n",
    "                 hidden_dim_encoder, input_recurrent_dim_encoder, output_recurrent_dim_encoder,\n",
    "                 input_recurrent_dim_decoder, output_recurrent_dim_decoder, k=2\n",
    "                 ):\n",
    "        super(GraphSeqGenerator, self).__init__()\n",
    "        # Useful Parameters\n",
    "        self.node_feature_dim = node_features_dim\n",
    "        self.in_edge_channels = in_edge_channels\n",
    "        self.seq_length = seq_length\n",
    "        self.k = k\n",
    "\n",
    "        # Encoder Parameters\n",
    "        self.hidden_dim_encoder = hidden_dim_encoder\n",
    "        self.input_recurrent_dim_encoder = input_recurrent_dim_encoder\n",
    "        self.output_recurrent_dim_encoder = output_recurrent_dim_encoder\n",
    "\n",
    "        # Decoder Parameters\n",
    "        self.input_recurrent_dim_decoder = input_recurrent_dim_decoder\n",
    "        self.output_recurrent_dim_decoder = output_recurrent_dim_decoder\n",
    "\n",
    "        print(\"Bruh\", self.input_recurrent_dim_encoder, self.output_recurrent_dim_encoder, self.hidden_dim_encoder)\n",
    "        self.encoder = Encoder(\n",
    "                                input_recurrent_dim=self.input_recurrent_dim_encoder,\n",
    "                                output_recurrent_dim=self.output_recurrent_dim_encoder,\n",
    "                                hidden_dim=self.hidden_dim_encoder,\n",
    "                                k=self.k\n",
    "                                )\n",
    "        print(\"Brah\", self.node_feature_dim, self.input_recurrent_dim_decoder, self.output_recurrent_dim_decoder )\n",
    "        self.decoder = Decoder(\n",
    "                                node_feature_dim=self.node_feature_dim,\n",
    "                                input_recurrent_dim=self.input_recurrent_dim_decoder,\n",
    "                                output_recurrent_dim=self.output_recurrent_dim_decoder,\n",
    "                                k=self.k\n",
    "                                )\n",
    "\n",
    "    def forward(self, snapshot, device):\n",
    "        prev_encoder_h, prev_decoder_h = None, None\n",
    "        for seq_num in range(self.seq_length):\n",
    "            #print(snapshot.x[seq_num].shape, snapshot.edge_index.shape, snapshot.edge_attr[seq_num][:, 1].shape,snapshot.y.shape)\n",
    "            node_features = snapshot.x[seq_num].to(device)\n",
    "            edge_index = snapshot.edge_index.to(device)\n",
    "            edge_attr = snapshot.edge_attr[seq_num].to(device)\n",
    "\n",
    "            curr_encoder_h = self.encoder(node_features, edge_index, edge_attr, prev_encoder_h)\n",
    "            prev_encoder_h = curr_encoder_h\n",
    "            print(curr_encoder_h.shape)\n",
    "            \n",
    "            y_hat, curr_decoder_h = self.decoder(curr_encoder_h, edge_index, edge_attr, prev_decoder_h)\n",
    "            prev_decoder_h = curr_decoder_h\n",
    "            # print('*******************')\n",
    "            # print(curr_decoder_h.shape)\n",
    "            # print(y_hat.shape)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bruh 4 16 64\n",
      "Brah 4 64 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphSeqGenerator(\n",
       "  (encoder): Encoder(\n",
       "    (recurrent): GConvGRU(\n",
       "      (conv_x_z): CustomChebConv(4, 16, K=2, normalization=sym)\n",
       "      (conv_h_z): CustomChebConv(16, 16, K=2, normalization=sym)\n",
       "      (conv_x_r): CustomChebConv(4, 16, K=2, normalization=sym)\n",
       "      (conv_h_r): CustomChebConv(16, 16, K=2, normalization=sym)\n",
       "      (conv_x_h): CustomChebConv(4, 16, K=2, normalization=sym)\n",
       "      (conv_h_h): CustomChebConv(16, 16, K=2, normalization=sym)\n",
       "    )\n",
       "    (linear): Linear(in_features=16, out_features=64, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (recurrent): GConvGRU(\n",
       "      (conv_x_z): CustomChebConv(64, 16, K=2, normalization=sym)\n",
       "      (conv_h_z): CustomChebConv(16, 16, K=2, normalization=sym)\n",
       "      (conv_x_r): CustomChebConv(64, 16, K=2, normalization=sym)\n",
       "      (conv_h_r): CustomChebConv(16, 16, K=2, normalization=sym)\n",
       "      (conv_x_h): CustomChebConv(64, 16, K=2, normalization=sym)\n",
       "      (conv_h_h): CustomChebConv(16, 16, K=2, normalization=sym)\n",
       "    )\n",
       "    (linear): Linear(in_features=16, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = GraphSeqGenerator(node_features_dim=4, in_edge_channels=2, seq_length=5, \n",
    "                  hidden_dim_encoder=64, input_recurrent_dim_encoder=4, output_recurrent_dim_encoder=16,\n",
    "                  input_recurrent_dim_decoder=64, output_recurrent_dim_decoder=16)\n",
    "device = torch.device('cpu')\n",
    "\n",
    "generator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/9995 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 4]) torch.Size([2, 4950]) torch.Size([4950, 2])\n",
      "Bruh torch.Size([100, 16])\n",
      "Bruh2 torch.Size([100, 64])\n",
      "torch.Size([100, 64])\n",
      "torch.Size([100, 4]) torch.Size([2, 4950]) torch.Size([4950, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (100x64 and 16x16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      6\u001b[0m        \u001b[38;5;28;01mfor\u001b[39;00m time, snapshot \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_data), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m, total\u001b[38;5;241m=\u001b[39mtrain_data\u001b[38;5;241m.\u001b[39msnapshot_count):\n\u001b[0;32m----> 7\u001b[0m               y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43msnapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m               cost \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(y_hat, snapshot\u001b[38;5;241m.\u001b[39my[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m      9\u001b[0m               cost\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml2/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml2/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[53], line 46\u001b[0m, in \u001b[0;36mGraphSeqGenerator.forward\u001b[0;34m(self, snapshot, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m snapshot\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     44\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m snapshot\u001b[38;5;241m.\u001b[39medge_attr[seq_num]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 46\u001b[0m curr_encoder_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_encoder_h\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m prev_encoder_h \u001b[38;5;241m=\u001b[39m curr_encoder_h\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(curr_encoder_h\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml2/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml2/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[50], line 11\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x, edge_index, edge_attr, H)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_attr, H\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape, edge_index\u001b[38;5;241m.\u001b[39mshape, edge_attr\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 11\u001b[0m     encoder_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecurrent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     encoder_h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(encoder_h)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBruh\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoder_h\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml2/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml2/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[43], line 56\u001b[0m, in \u001b[0;36mGConvGRU.forward\u001b[0;34m(self, X, edge_index, edge_weight, H, lambda_max)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, edge_index, edge_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, H\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, lambda_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     55\u001b[0m     H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_hidden_state(X, H)\n\u001b[0;32m---> 56\u001b[0m     Z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_update_gate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     R \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_reset_gate(X, edge_index, edge_weight, H, lambda_max)\n\u001b[1;32m     58\u001b[0m     H_tilde \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_candidate_state(X, edge_index, edge_weight, H, R, lambda_max)\n",
      "Cell \u001b[0;32mIn[43], line 34\u001b[0m, in \u001b[0;36mGConvGRU._calculate_update_gate\u001b[0;34m(self, X, edge_index, edge_weight, H, lambda_max)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_calculate_update_gate\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, edge_index, edge_weight, H, lambda_max):\n\u001b[1;32m     33\u001b[0m     Z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_x_z(X, edge_index, edge_weight, lambda_max\u001b[38;5;241m=\u001b[39mlambda_max)\n\u001b[0;32m---> 34\u001b[0m     Z \u001b[38;5;241m=\u001b[39m Z \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_h_z\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     Z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(Z)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Z\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml2/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml2/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml2/lib/python3.11/site-packages/torch_geometric/nn/conv/cheb_conv.py:163\u001b[0m, in \u001b[0;36mChebConv.forward\u001b[0;34m(self, x, edge_index, edge_weight, batch, lambda_max)\u001b[0m\n\u001b[1;32m    161\u001b[0m Tx_0 \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    162\u001b[0m Tx_1 \u001b[38;5;241m=\u001b[39m x  \u001b[38;5;66;03m# Dummy.\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlins\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTx_0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, norm: Tensor)\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlins) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml2/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml2/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aiml2/lib/python3.11/site-packages/torch_geometric/nn/dense/linear.py:147\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (100x64 and 16x16)"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(generator.parameters(), lr=0.01)\n",
    "\n",
    "generator.train()\n",
    "\n",
    "for epoch in range(3):\n",
    "       for time, snapshot in tqdm(enumerate(train_data), desc='Train', total=train_data.snapshot_count):\n",
    "              y_hat = generator(snapshot, device)\n",
    "              cost = F.mse_loss(y_hat, snapshot.y[0].to(device))\n",
    "              cost.backward()\n",
    "              optimizer.step()\n",
    "              optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.snapshot_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, filters):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = GConvGRU(node_features, filters, 2)\n",
    "        self.linear = torch.nn.Linear(filters, 4)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, H=None):\n",
    "        #print(x.shape, edge_index.shape, edge_weight.shape)\n",
    "        h = self.recurrent(x, edge_index, edge_weight, H)\n",
    "        x = F.relu(h)\n",
    "        x = self.linear(x)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecurrentGCN(node_features=4, filters=32)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0].x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0].x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note to self chebconv supports only one dimension edge_attr\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(3):\n",
    "    for time, snapshot in tqdm(enumerate(train_data), desc='Train', total=train_data.snapshot_count):\n",
    "        h_t_prev = None\n",
    "        for seq_num in range(train_data[0].x.shape[0]):\n",
    "            #print(snapshot.x[seq_num].shape, snapshot.edge_index.shape, snapshot.edge_attr[seq_num][:, 1].shape,snapshot.y.shape)\n",
    "            y_hat, h_t = model(snapshot.x[seq_num], snapshot.edge_index, snapshot.edge_attr[seq_num], h_t_prev)\n",
    "            # print(y_hat.shape, h_t.shape)\n",
    "            h_t_prev = h_t\n",
    "            \n",
    "        cost = torch.mean((y_hat-snapshot.y[0])**2)\n",
    "        print('Loss', cost)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, filters):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = GConvGRU(node_features, filters, 2)\n",
    "        self.linear = torch.nn.Linear(filters, 4)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, H=None):\n",
    "        h = self.recurrent(x, edge_index, edge_weight, H)\n",
    "        x = F.relu(h)\n",
    "        x = self.linear(x)\n",
    "        return x, h\n",
    "\n",
    "\n",
    "model = RecurrentGCN(node_features=4, filters=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(3):\n",
    "    for time, snapshot in tqdm(enumerate(train_data), desc='Train', total=train_data.snapshot_count):\n",
    "        h_t_prev = None\n",
    "        for seq_num in range(train_data[0].x.shape[0]):\n",
    "            y_hat, h_t = model(snapshot.x[seq_num], snapshot.edge_index, snapshot.edge_attr[seq_num], h_t_prev)\n",
    "            h_t_prev = h_t\n",
    "\n",
    "        cost = F.mse_loss(y_hat, snapshot.y[0])\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming undo_minmax_scale, final_min_node_feat, final_max_node_feat, and train_data are defined\n",
    "\n",
    "model.eval()\n",
    "cost = 0\n",
    "frames = []\n",
    "\n",
    "for time, snapshot in tqdm(enumerate(train_data), desc='Train', total=train_data.snapshot_count):\n",
    "    h_t_prev = None\n",
    "    for seq_num in range(train_data[0].x.shape[0]):\n",
    "        y_hat, h_t = model(snapshot.x[seq_num], snapshot.edge_index, snapshot.edge_attr[seq_num], h_t_prev)\n",
    "        h_t_prev = h_t\n",
    "        \n",
    "    y_hat_scaled = undo_minmax_scale([y_hat.numpy(force=True)], final_min_node_feat, final_max_node_feat)[0]\n",
    "    y_actual_scaled = undo_minmax_scale([snapshot.y[0].numpy(force=True)], final_min_node_feat, final_max_node_feat)[0]\n",
    "\n",
    "    y_hat_scaled_x = y_hat_scaled[:, 0]\n",
    "    y_hat_scaled_y = y_hat_scaled[:, 1]\n",
    "    y_actual_scaled_x = y_actual_scaled[:, 0]\n",
    "    y_actual_scaled_y = y_actual_scaled[:, 1]\n",
    "    \n",
    "    # Plot the predicted vs actual values\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.scatter(list(y_hat_scaled_x), list(y_hat_scaled_y), label='Predicted', alpha=0.6)\n",
    "    ax.scatter(list(y_actual_scaled_x), list(y_actual_scaled_y), label='Actual', alpha=0.6)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.legend()\n",
    "    ax.set_title('Predicted vs Actual Values')\n",
    "    \n",
    "    # Save the current plot as a frame\n",
    "    fig.canvas.draw()\n",
    "    frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    frames.append(Image.fromarray(frame))\n",
    "    plt.close(fig)\n",
    "    \n",
    "    cost = cost + torch.mean((y_hat - snapshot.y[0])**2)\n",
    "    cost = cost / (time + 1)\n",
    "    cost = cost.item()\n",
    "    #print(\"MSE: {:.4f}\".format(cost))\n",
    "\n",
    "# Save frames as a GIF\n",
    "frames[0].save('predicted_vs_actual.gif', save_all=True, append_images=frames[1:], duration=500, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "cost = 0\n",
    "for time, snapshot in tqdm(enumerate(train_data), desc='Train', total=train_data.snapshot_count):\n",
    "    h_t_prev = None\n",
    "    for seq_num in range(train_data[0].x.shape[0]):\n",
    "        y_hat, h_t = model(snapshot.x[seq_num], snapshot.edge_index, snapshot.edge_attr[seq_num], h_t_prev)\n",
    "        # print(y_hat.shape, h_t.shape)\n",
    "        h_t_prev = h_t\n",
    "        \n",
    "    # y_hat_x = y_hat[:, 0].numpy(force=True)\n",
    "    # y_hat_y = y_hat[:, 1].numpy(force=True)\n",
    "    # actual_x = snapshot.y[0][:, 0].numpy(force=True)\n",
    "    # actual_y = snapshot.y[0][:, 1].numpy(force=True)\n",
    "    y_hat_scaled = undo_minmax_scale([y_hat.numpy(force=True)], final_min_node_feat, final_max_node_feat)[0]\n",
    "    y_actual_scaled = undo_minmax_scale([snapshot.y[0].numpy(force=True)], final_min_node_feat, final_max_node_feat)[0]\n",
    "\n",
    "    y_hat_scaled_x = y_hat_scaled[:, 0]\n",
    "    y_hat_scaled_y = y_hat_scaled[:, 1]\n",
    "    y_actual_scaled_x = y_actual_scaled[:, 0]\n",
    "    y_actual_scaled_y = y_actual_scaled[:, 1]\n",
    "    #print(type(y_hat_x))\n",
    "    \n",
    "    # Plot the predicted vs actual values\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(list(y_hat_scaled_x), list(y_hat_scaled_y), label='Predicted', alpha=0.6)\n",
    "    plt.scatter(list(y_actual_scaled_x), list(y_actual_scaled_y), label='Actual', alpha=0.6)\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.legend()\n",
    "    plt.title('Predicted vs Actual Values')\n",
    "    plt.show()\n",
    "    cost = cost + torch.mean((y_hat-snapshot.y[0])**2)\n",
    "    cost = cost / (time+1)\n",
    "    cost = cost.item()\n",
    "    print(\"MSE: {:.4f}\".format(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temporal_graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
