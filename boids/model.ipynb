{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pygame\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data, InMemoryDataset, download_url, TemporalData\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.nn import ChebConv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting CSV To Input For Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing Our CSV And Converting To DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>Boids</th>\n",
       "      <th>Simulation</th>\n",
       "      <th>Timestep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192.032076</td>\n",
       "      <td>413.277323</td>\n",
       "      <td>-1.768924</td>\n",
       "      <td>-0.825558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>266.236092</td>\n",
       "      <td>98.829753</td>\n",
       "      <td>1.131848</td>\n",
       "      <td>2.606990</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.612704</td>\n",
       "      <td>129.962456</td>\n",
       "      <td>-4.415965</td>\n",
       "      <td>-2.354997</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536.605412</td>\n",
       "      <td>33.303273</td>\n",
       "      <td>-3.424230</td>\n",
       "      <td>4.601926</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>679.053022</td>\n",
       "      <td>882.292871</td>\n",
       "      <td>1.094493</td>\n",
       "      <td>0.031586</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x           y        dx        dy  Boids  Simulation  Timestep\n",
       "0  192.032076  413.277323 -1.768924 -0.825558      0           0         0\n",
       "1  266.236092   98.829753  1.131848  2.606990      1           0         0\n",
       "2   62.612704  129.962456 -4.415965 -2.354997      2           0         0\n",
       "3  536.605412   33.303273 -3.424230  4.601926      3           0         0\n",
       "4  679.053022  882.292871  1.094493  0.031586      4           0         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_sim = '../data/simulation.csv'\n",
    "sim_df = pd.read_csv(path_to_sim)\n",
    "\n",
    "sim_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Boid_i</th>\n",
       "      <th>Boid_j</th>\n",
       "      <th>Timestep</th>\n",
       "      <th>Simulation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Boid_i  Boid_j  Timestep  Simulation\n",
       "0       0      39         0           0\n",
       "1       0      57         0           0\n",
       "2       1      32         0           0\n",
       "3       1      34         0           0\n",
       "4       1      83         0           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_sim_edges = '../data/simulation_edges.csv'\n",
    "sim_edges_df = pd.read_csv(path_to_sim_edges)\n",
    "\n",
    "sim_edges_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting DataFrame To Data Object From Pytorch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDataGraph(sim_df, sim_edges_df, node_features_names):\n",
    "    \"\"\"\n",
    "    Converts simulation data into a PyTorch Geometric Data object.\n",
    "\n",
    "    Parameters:\n",
    "    - sim_df (DataFrame): DataFrame containing node features for a specific simulation and timestep.\n",
    "    - sim_edges_df (DataFrame): DataFrame containing edge information for the simulation.\n",
    "    - node_features_names (list of str): Names of the columns in sim_df that are node features.\n",
    "\n",
    "    Returns:\n",
    "    - Data: A PyTorch Geometric Data object representing the graph for the simulation.\n",
    "    \"\"\"\n",
    "    # Convert node features and edge information into tensors\n",
    "    node_features = torch.tensor(sim_df[node_features_names].to_numpy(), dtype=torch.float)\n",
    "    edge_index = torch.tensor(sim_edges_df[['Boid_i', 'Boid_j']].to_numpy().T, dtype=torch.long)\n",
    "    edge_attributes = torch.tensor(np.ones((sim_edges_df.shape[0], 1)), dtype=torch.float)\n",
    "\n",
    "    # Create and return the Data object\n",
    "    graph = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attributes)\n",
    "    return graph\n",
    "\n",
    "def allDataGraph(sim_df, sim_edges_df):\n",
    "    \"\"\"\n",
    "    Generates a list of PyTorch Geometric Data objects for each simulation and timestep.\n",
    "\n",
    "    Parameters:\n",
    "    - sim_df (DataFrame): DataFrame containing node features for all simulations and timesteps.\n",
    "    - sim_edges_df (DataFrame): DataFrame containing edge information for all simulations and timesteps.\n",
    "\n",
    "    Returns:\n",
    "    - list of Data: A list of PyTorch Geometric Data objects, one for each simulation and timestep.\n",
    "    \"\"\"\n",
    "    # Group the data by simulation and timestep\n",
    "    sim_gb_df = sim_df.groupby(['Timestep', 'Simulation'])\n",
    "    sim_edges_gb_df = sim_edges_df.groupby(['Timestep', 'Simulation'])\n",
    "\n",
    "    graphs = []\n",
    "    # Iterate over each group and convert to a Data object\n",
    "    for key, _ in sim_gb_df:\n",
    "        curr_sim_df = sim_gb_df.get_group(key)\n",
    "        curr_sim_edges_df = sim_edges_gb_df.get_group(key)\n",
    "        curr_graph = toDataGraph(curr_sim_df, curr_sim_edges_df, ['x', 'y', 'dx', 'dy'])\n",
    "        graphs.append(curr_graph)\n",
    "\n",
    "    return graphs\n",
    "\n",
    "# Example usage\n",
    "graphs = allDataGraph(sim_df, sim_edges_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: NEXT STEP MAKES CLASS THAT GIVEN THE SIMULATION DATAFRAME AND SIMULATION EDGES DATAFRAME CREATES A DATASET OBJECT\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, sim_df, sim_edges_df):\n",
    "        super(CustomDataset).__init__()\n",
    "        self.all_graphs = allDataGraph(sim_df, sim_edges_df)\n",
    "        self.sequences = [graphs[i-5:i-1] for i in range(5, len(self.all_graphs)+1)]\n",
    "        self.labels = [graphs[i-1] for i in range(5, len(self.all_graphs)+1)]\n",
    "        self.len = len(self.labels)\n",
    "    def __getitem__(self, index):\n",
    "        return self.sequences[index], self.labels[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "dataset = CustomDataset(sim_df, sim_edges_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GConvGRU(torch.nn.Module):\n",
    "    \n",
    "#------------------------------------------------------------------------init\n",
    "    def __init__( self, in_channels: int, out_channels: int, K: int,normalization: str = \"sym\",bias: bool = True ):\n",
    "        super(GConvGRU, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.normalization = normalization\n",
    "        self.bias = bias\n",
    "        self._create_parameters_and_layers()\n",
    "\n",
    "    def _create_update_gate_parameters_and_layers(self):\n",
    "        self.conv_x_z = ChebConv(in_channels=self.in_channels,out_channels=self.out_channels, K=self.K, normalization=self.normalization, bias=self.bias)\n",
    "        self.conv_h_z = ChebConv(in_channels=self.out_channels,out_channels=self.out_channels, K=self.K, normalization=self.normalization, bias=self.bias)\n",
    "\n",
    "    def _create_reset_gate_parameters_and_layers(self):\n",
    "        self.conv_x_r = ChebConv( in_channels=self.in_channels,out_channels=self.out_channels, K=self.K,  normalization=self.normalization, bias=self.bias )\n",
    "        self.conv_h_r = ChebConv( in_channels=self.out_channels,out_channels=self.out_channels, K=self.K,  normalization=self.normalization, bias=self.bias )\n",
    "\n",
    "    def _create_candidate_state_parameters_and_layers(self):\n",
    "        self.conv_x_h = ChebConv(  in_channels=self.in_channels, out_channels=self.out_channels, K=self.K,normalization=self.normalization,bias=self.bias)\n",
    "        self.conv_h_h = ChebConv(  in_channels=self.out_channels, out_channels=self.out_channels, K=self.K,normalization=self.normalization,bias=self.bias)\n",
    "\n",
    "    def _create_parameters_and_layers(self):\n",
    "        self._create_update_gate_parameters_and_layers()\n",
    "        self._create_reset_gate_parameters_and_layers()\n",
    "        self._create_candidate_state_parameters_and_layers()\n",
    "        \n",
    "#-------------------------------------------------------------------------------------------\n",
    "    def _set_hidden_state(self, X): # step 1\n",
    "        H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n",
    "        return H\n",
    "#---------------------------------------------------\n",
    "    def _calculate_update_gate(self, X, edge_index, edge_weight, H): # step 2\n",
    "        Z = self.conv_x_z(X, edge_index, edge_weight)\n",
    "        Z = Z + self.conv_h_z(H, edge_index, edge_weight)\n",
    "        Z = torch.sigmoid(Z)\n",
    "        return Z\n",
    "#------------------------------------------------------\n",
    "    def _calculate_reset_gate(self, X, edge_index, edge_weight, H):\n",
    "        R = self.conv_x_r(X, edge_index, edge_weight)\n",
    "        R = R + self.conv_h_r(H, edge_index, edge_weight)\n",
    "        R = torch.sigmoid(R)\n",
    "        return R\n",
    "#------------------------- # Step 4\n",
    "    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R):\n",
    "        H_tilde = self.conv_x_h(X, edge_index, edge_weight)\n",
    "        H_tilde = H_tilde + self.conv_h_h(H * R, edge_index, edge_weight)\n",
    "        H_tilde = torch.tanh(H_tilde)\n",
    "        return H_tilde\n",
    "\n",
    "#-------------------------------\n",
    "    def _calculate_hidden_state(self, Z, H, H_tilde):\n",
    "        H = Z * H + (1 - Z) * H_tilde\n",
    "        return H\n",
    "\n",
    "    def forward( self, X: torch.FloatTensor, edge_index: torch.LongTensor, edge_weight: torch.FloatTensor = None) -> torch.FloatTensor:\n",
    "        H = self._set_hidden_state(X) # step 1 # X (20,4) H (20,32)\n",
    "        Z = self._calculate_update_gate(X, edge_index, edge_weight, H) # step 2 Z (20, 32)\n",
    "        R = self._calculate_reset_gate(X, edge_index, edge_weight, H) # step 3  R (20, 32)\n",
    "        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R) # step 4 H_tilde (20, 32)\n",
    "        \n",
    "        H = self._calculate_hidden_state(Z, H, H_tilde) # step 5  H (20, 32)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, node_feature_dim, hidden_dim, recurrent_dim, output_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = GCNConv(node_feature_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, recurrent_dim)\n",
    "        self.reccurent = GConvGRU(recurrent_dim,output_dim)\n",
    "    \n",
    "    def forward(self,x,edge_index,edge_weight,H=None):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = torch.relu(x)\n",
    "        encoder_h = self.reccurent(x,edge_index,edge_weight,H)\n",
    "        return encoder_h\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, node_feature_dim, hidden_dim, recurrent_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.recurrent = GConvGRU(output_dim, recurrent_dim)\n",
    "        self.conv2 = GCNConv(recurrent_dim, hidden_dim)\n",
    "        self.conv1 = GCNConv(hidden_dim, node_feature_dim)\n",
    "\n",
    "    def forward(self, h, edge_index, edge_weight, H=None):\n",
    "        decoder_h = self.recurrent(h, edge_index, edge_weight, H)\n",
    "        x = torch.relu(decoder_h)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        return x, decoder_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSeqGenerator(nn.Module):\n",
    "    def __init__(self, obs_len, pred_len, \n",
    "                 node_feature_dim, \n",
    "                 encoder_hidden_dim, encoder_recurrent_dim, enconder_output_dim,\n",
    "                 decoder_hidden_dim, decoder_recurrent_dim, decoder_output_dim,\n",
    "                 device,\n",
    "                 noise_dim=(0, ), noise_type='gaussian', noise_mix_type='ped', \n",
    "                ):\n",
    "        \n",
    "        self.obs_len = obs_len\n",
    "        self.pred_len = pred_len\n",
    "        self.node_feature_dim = node_feature_dim\n",
    "\n",
    "        self.encoder_hidden_dim = encoder_hidden_dim\n",
    "        self.encoder_recurrent_dim = encoder_recurrent_dim\n",
    "        self.enconder_output_dim = enconder_output_dim\n",
    "\n",
    "        self.decoder_hidden_dim = decoder_hidden_dim\n",
    "        self.decoder_recurrent_dim = decoder_recurrent_dim\n",
    "        self.decoder_output_dim = decoder_output_dim\n",
    "\n",
    "        self.noise_dim = noise_dim\n",
    "        self.noise_type = noise_type\n",
    "        self.noise_mix_type = noise_mix_type\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "                                node_feature_dim=self.node_feature_dim,\n",
    "                                hidden_dim=self.encoder_hidden_dim,\n",
    "                                recurrent_dim=self.encoder_recurrent_dim,\n",
    "                                output_dim=self.enconder_output_dim\n",
    "                                )\n",
    "        \n",
    "        self.decoder = Decoder(\n",
    "                                node_feature_dim=self.node_feature_dim,\n",
    "                                hidden_dim=self.decoder_hidden_dim,\n",
    "                                recurrent_dim=self.decoder_recurrent_dim,\n",
    "                                output_dim=self.decoder_output_dim\n",
    "                                )\n",
    "        \n",
    "        if self.noise_dim[0] == 0:\n",
    "            self.noise_dim = None\n",
    "        else:\n",
    "            self.noise_first_dim = noise_dim[0]\n",
    "        \n",
    "        def get_noise(self, shape, noise_type):\n",
    "            if noise_type == 'gaussian':\n",
    "                return torch.randn(*shape).to(device)\n",
    "            elif noise_type == 'uniform':\n",
    "                return torch.rand(*shape).sub_(0.5).mul_(2.0).to(device)\n",
    "            raise ValueError('Unrecognized noise type \"%s\"' % noise_type)\n",
    "\n",
    "        def add_noise(self, _input, user_noise=None):\n",
    "            \"\"\"\n",
    "            Inputs:\n",
    "            - _input: Tensor of shape (_, decoder_h_dim - noise_first_dim)\n",
    "            - user_noise: Generally used for inference when you want to see\n",
    "            relation between different types of noise and outputs.\n",
    "            Outputs:\n",
    "            - decoder_h: Tensor of shape (_, decoder_h_dim)\n",
    "            Example:\n",
    "\n",
    "            Here _input.size(0) is the number of boids (weren't doing batches yet).\n",
    "            Let's say 100. Lets say self.noise_dim is '(64,)', the noise shape\n",
    "            will be (100, 64). So then we concat, (100, num_feat) with (100,64) tensor\n",
    "            along dim=1, then we get a resulting vector, (100, num_feat + 64)\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            noise_shape = (_input.size(0), ) + self.noise_dim\n",
    "\n",
    "            if user_noise is not None:\n",
    "                z_decoder = user_noise\n",
    "            else:\n",
    "                z_decoder = self.get_noise(noise_shape, self.noise_type)\n",
    "\n",
    "            decoder_h = torch.cat([_input, z_decoder], dim=1)\n",
    "\n",
    "            return decoder_h\n",
    "\n",
    "    def forward(self, seq):\n",
    "        encoder_hidden_states = []\n",
    "        prev_encoder_H = None\n",
    "\n",
    "        # First get the hidden states from encoder\n",
    "        for graph in seq:\n",
    "            curr_encoder_h = self.encoder(graph.x, graph.edge_index, graph.edge_weight, prev_encoder_H)\n",
    "            encoder_hidden_states.append(curr_encoder_h)\n",
    "            prev_encoder_H = curr_encoder_h\n",
    "            \n",
    "        # Second add noise to the hidden states from encoder to feed it to decoder\n",
    "        encoder_hidden_states = [self.add_noise(h) for h in encoder_hidden_states]\n",
    "        \n",
    "        # Third pass in noisy hidden states from encoder to decoder and get last output of decoder\n",
    "        prev_decoder_H = None\n",
    "        for i, graph in enumerate(seq):\n",
    "            x, curr_decoder_h = self.decoder(encoder_hidden_states[i], graph.x, graph.edge_index, prev_decoder_H)\n",
    "            prev_decoder_H = curr_decoder_h\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GraphSeqDiscriminator(nn.Module):\n",
    "    def __init__(self, node_feature_dim, hidden_dim, recurrent_dim, output_dim):\n",
    "        self.node_feature_dim = node_feature_dim\n",
    "        self.encoder_hidden_dim = hidden_dim\n",
    "        self.encoder_recurrent_dim = recurrent_dim\n",
    "        self.enconder_output_dim = output_dim\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "                                node_feature_dim=self.node_feature_dim,\n",
    "                                hidden_dim=self.encoder_hidden_dim,\n",
    "                                recurrent_dim=self.encoder_recurrent_dim,\n",
    "                                output_dim=self.enconder_output_dim\n",
    "                                )\n",
    "        self.linear = nn.Linear(self.enconder_output_dim, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, seq):\n",
    "        encoder_hidden_states = []\n",
    "        prev_encoder_H = None\n",
    "\n",
    "        # First get the hidden states from encoder\n",
    "        for graph in seq:\n",
    "            curr_encoder_h = self.encoder(graph.x, graph.edge_index, graph.edge_weight, prev_encoder_H)\n",
    "            encoder_hidden_states.append(curr_encoder_h)\n",
    "            prev_encoder_H = curr_encoder_h\n",
    "            \n",
    "        x = self.relu(self.linear(curr_encoder_h))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges_tensor(data, threshold):\n",
    "    \"\"\"\n",
    "    Calculates edges based on a distance threshold for a tensor where the first two columns represent 'x' and 'y' coordinates,\n",
    "    and formats them in COO (Coordinate List) format with shape [2, num_edges].\n",
    "\n",
    "    Parameters:\n",
    "    - data: A tensor where each row is a point in 2D space, with the first two columns being 'x' and 'y' coordinates.\n",
    "    - threshold: The distance threshold to consider two points as connected.\n",
    "\n",
    "    Returns:\n",
    "    - edges_coo: A tensor in COO format with shape [2, num_edges], where the first row contains the source nodes and the second row contains the target nodes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate pairwise distances only for 'x' and 'y'\n",
    "    x_y = data[:, :2]  # Extract 'x' and 'y' columns\n",
    "    distances = torch.cdist(x_y, x_y)  # Compute pairwise distances\n",
    "\n",
    "    # Identify pairs within the threshold distance\n",
    "    close_pairs = distances < threshold\n",
    "\n",
    "    # Extract indices of close pairs\n",
    "    edges = torch.nonzero(close_pairs, as_tuple=False).type(torch.long)\n",
    "\n",
    "    # Filter out upper triangle including diagonal to avoid duplicates and self-connections\n",
    "    edges_filtered = edges[edges[:, 0] < edges[:, 1]]\n",
    "\n",
    "    # Transpose to get shape [2, num_edges]\n",
    "    edges_coo = edges_filtered.t()\n",
    "\n",
    "    return edges_coo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataset, generator_model, discriminator_model, criterion_g, criterion_d, optimizer_g, optimizer_d, device):\n",
    "    '''\n",
    "    Loops through the entire dataset for training.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: The dataset to train on.\n",
    "    - criterion_g: The loss function for the generator.\n",
    "    - criterion_d: The loss function for the discriminator.\n",
    "    - optimizer_g: The optimizer for the generator.\n",
    "    - optimizer_d: The optimizer for the discriminator.\n",
    "\n",
    "    '''\n",
    "    for i, (seq, next_graph_of_seq) in tqdm(enumerate(dataset), desc='Train'):\n",
    "        # Putting sequences in device\n",
    "        seq, real_next_graph_of_seq = [graph.to(device) for graph in seq], next_graph_of_seq.to(device)\n",
    "        # Get output of generator which is just node features\n",
    "        fake_graph_node_feats = generator_model(seq)\n",
    "        # Get the edges of the fake_graph_node_feats\n",
    "        edge_index = get_edges_tensor(fake_next_graph_of_seq, threshold=75)\n",
    "        # Set up edge attributes too\n",
    "        edge_attr = torch.ones((edge_index.size(dim=1), 1))\n",
    "        # Set up a Data Object from Pytorch Geometric\n",
    "        fake_next_graph_of_seq = Data(fake_graph_node_feats, edge_index, edge_attr).to(device)\n",
    "        # Creating fake sequence and real sequence where the first couple are real and the last is either predictied or real\n",
    "        real_seq = seq\n",
    "        fake_seq = seq\n",
    "\n",
    "        real_seq.append(real_next_graph_of_seq)\n",
    "        fake_seq.append(fake_next_graph_of_seq)\n",
    "        discriminator_model(real_seq)\n",
    "\n",
    "        \"\"\"         \n",
    "        Part 1 Train Discriminator\n",
    "        1. Pass in real sequence to discriminator. Calculate loss: loss(log(D(x))) (backward pass) | loss(prob. its real, itsreal) ex. loss(0.7, 1)\n",
    "        2. Pass in fake sequence from the current generator to discriminator. Calculate loss: loss(log(1-D(G(z)))) (backward pass) | loss(prob its. real, its fake) ex. loss(0.2, 0)\n",
    "        3. Step for optimizer of discriminator \n",
    "        \"\"\"\n",
    "    \n",
    "        \"\"\"  \n",
    "        Part 2 Train Generator\n",
    "        1. Pass in fake sequence from current generator to discriminator. Calculate loss (using real labels for loss) | loss(its real, its real)\n",
    "        2. Update using backward pass and step into optimizer\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
